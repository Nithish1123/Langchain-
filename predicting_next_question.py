# -*- coding: utf-8 -*-
"""Predicting next question

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X-_TQla4sSpsaHgCOFCfvS5vwc7qiFXh
"""

from langchain.vectorstores import FAISS
from langchain.document_loaders.csv_loader import CSVLoader
from langchain_openai import ChatOpenAI
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from jina import Executor, requests, Document, DocumentArray
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
        ChatPromptTemplate,
        SystemMessagePromptTemplate,
        HumanMessagePromptTemplate,
    )
from langchain.chains import LLMChain, ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
import fitz
import os
os.environ['OPENAI_API_KEY'] = "openkey"
llm = OpenAI(temperature=0.1)
embedding_vector = OpenAIEmbeddings()



def extract_text_from_pdf(file_path):
    text = ""
    try:
        doc = fitz.open(file_path)
        for page_num in range(doc.page_count):
            page = doc.load_page(page_num)
            text += page.get_text()
        doc.close()
    except Exception as e:
        print(f"Error extracting text from PDF: {e}")
    return text

file_path = '/content/GO-TO-MARKET STRATEGY (GTM) (1).pdf'
pdf_text = extract_text_from_pdf(file_path)

def get_qa_chain():
   data = pdf_text
   text_splitter = RecursiveCharacterTextSplitter(
        separators=['\n\n', '\n', '.', ','],
        chunk_size=1000
    )
   docs = text_splitter.create_documents([pdf_text])

   embeddings = OpenAIEmbeddings()
   vectordb = FAISS.from_documents(docs, embeddings)

    # Create a retriever for querying the vector database
   retriever = vectordb.as_retriever(score_threshold=0.7)

   prompt_template = """Given the following context and a question, generate an answer based on this context only.
    In the answer try to provide as much text as possible from "response" section in the source document context without making much changes.
    If the answer is not found in the context, kindly state "I don't know." Don't try to make up an answer.

    CONTEXT: {context}

    QUESTION: {question}"""

   PROMPT = PromptTemplate(
        template=prompt_template, input_variables=["context", "question"]
    )

   chain = RetrievalQA.from_chain_type(llm=llm,
                                        chain_type="stuff",
                                        retriever=retriever,
                                        input_key="query",
                                        return_source_documents=True,
                                        chain_type_kwargs={"prompt": PROMPT})

   return chain



def predict_next_questions():
  data = pdf_text
  text_splitter = RecursiveCharacterTextSplitter(
        separators=['\n\n', '\n', '.', ','],
        chunk_size=1000
    )
  docs = text_splitter.create_documents([pdf_text])

  embeddings = OpenAIEmbeddings()
  vectordb = FAISS.from_documents(docs, embeddings)

    # Create a retriever for querying the vector database
  retriever = vectordb.as_retriever(score_threshold=0.7)
  # docs1 = retriever.get_relevant_documents("who Mahathi Bhagavatula's")

  template = """You are a helpful assistant in predicting next question based on current question. Give 3 question always
                  You always provide predicted question on new line"""
  system_message_prompt = SystemMessagePromptTemplate.from_template(template)
  human_template ="{text}"
  human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

  chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
  chain1 = LLMChain(
        llm = OpenAI(temperature=0.1),
        prompt=chat_prompt,
        verbose=True
    )

  return chain1

# docs1 = retriever.get_relevant_documents(user_input)
if __name__ == "__main__":
    create_vector_db()
    chain =get_qa_chain()
    user_input="who are data scienctist"
    print(chain(user_input))
    docs1 = retriever.get_relevant_documents(user_input)
    chain1=predict_next_questions()
    print(chain1(docs1))

